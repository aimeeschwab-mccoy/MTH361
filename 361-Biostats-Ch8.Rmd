---
title: 'Ch. 8: Inference for Categorical Data'
#subtitle: "<span style = 'font-size: 90%;'>Sections 1.1-1.3</span>"
author: "MTH 361: Probability and Statistics in the Health Sciences"
date: "Last updated: `r Sys.Date()`"
#institute: '`r icon::fa("twitter")` AimeeSMcCoy <br> `r icon::fa("envelope")` aimeeschwab-mccoy@creighton.edu'
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      titleSlideClass: ['left', 'middle', 'inverse']
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: inverse

# 8.1: Inference for a single proportion

- Sampling distribution of $\hat{p}$

--

- Confidence intervals for $p$ 

--

- Hypothesis tests for $p$

```{css, include=FALSE}
@media print {
  .has-continuation {
    display: block !important;
  }
}
```

```{r xaringan-setup, include=FALSE}
library(xaringanthemer)
library(xaringanExtra)
style_duo_accent(primary_color = "#0054a6",
                 secondary_color = "#f1fffe",
  header_font_google = google_font("Source Sans Pro"),
  text_font_google = google_font("Source Sans Pro"))

#xaringanExtra::use_logo(
#  image_url = "https://upload.wikimedia.org/wikipedia/en/thumb/f/f2/Creighton_University_seal.svg/1200px-Creighton_University_seal.svg.png"
#)


xaringanExtra::use_tachyons()

xaringanExtra::use_tile_view()

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.width=8, fig.height=5, cache=TRUE)

library(tidyverse)
library(RColorBrewer)
library(patchwork)
library(kableExtra)
library(oibiostat)
library(mosaic)
```

---

## Binomial data

.bg-washed-blue.b--blue.ba.ph3[
__Example__: Advanced melanoma is an aggressive form of skin cancer that, until recently, was almost uniformly fatal. Two therapies have seemed to be successful in triggering an immune response to this cancer: nivolumab and ipilimunab.

A 2013 report in the New England Journal of Medicine by Wolchok et al. reported the results of a study in which patients were treated with both nivolumab and ipilimumab. Fifty-three patients were given the new regimens concurrently, and the response to therapy could be evaluated in 52 of the 53. Of the 52 evaluable patients, 21 (40%) experienced a response according to commonly accepted criteria. In previous studies, the proportion of patients responding to one of these agents was 30% or less. How might one compare the new data to past results?
]

---

## Binomial data

.bg-washed-yellow.b--yellow.ba.ph3[
__Binomial variable__: a variable with only two possible outcomes (also called _binary variables_)

- The possible outcomes are referred to as __successes__ (the outcome we care about) and __failures__ (the outcome we don't).
]

--

When we have a binomial variable, our goal is usually to estimate the underlying __probability of success__, or __population proportion__, 

$$p$$

---

## Sampling distribution of $\hat{p}$

.bg-washed-yellow.b--yellow.ba.ph3[
The __sampling distribution of $\hat{p}$__ has:

- Mean: $np$ 

- Standard error: $SE_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}}$

- Shape: Approximately normally distributed, as long as the sample size is "large enough" 

$$np\ge 10$$

$$n(1-p) \ge 10$$
]

---

## Sampling distribution of $\hat{p}$

We can calculate confidence intervals and carry out hypothesis tests using this approximation...

--

... but we like to be accurate.

So instead, we'll use methods based on the __binomial distribution__.

---

## Binomial distribution

Assuming each observation is independent, we can get the formula for the __binomial distribution__ from the Multiplication Rule. Let $P(X=x)$ represent the probability that we have observed $x$ successes our of $n$ trials.

$$P(X=x)={n \choose x}p^{x}(1-p)^{n-x}$$

--

The binomial distribution is the "backbone" of the (1) binomial test, and (2) binomial interval.

---

## Binomial distribution

What does the binomial distribution “look like”? It depends on the parameters.

```{r, echo=FALSE}
x1 <- 0:10
x2 <- 0:50
p1 <- dbinom(x1, size=10, prob=0.5)
p2 <- dbinom(x1, size=10, prob=0.25)
p3 <- dbinom(x1, size=10, prob=0.1)
p4 <- dbinom(x2, size=50, prob=0.5)
p5 <- dbinom(x2, size=50, prob=0.25)
p6 <- dbinom(x2, size=50, prob=0.1)

data <- tibble(x = c(x1, x1, x1, x2, x2, x2),
               p = c(p1, p2, p3, p4, p5, p6),
               dist = c(rep('Binomial(n=10, p=0.5)', 11),
                        rep('Binomial(n=10, p=0.25)', 11),
                        rep('Binomial(n=10, p=0.1)', 11),
                        rep('Binomial(n=100, p=0.5)', 51),
                        rep('Binomial(n=100, p=0.25)', 51),
                        rep('Binomial(n=100, p=0.1)', 51)))

data %>% ggplot(aes(x=x, y=p)) + geom_col(aes(fill=dist)) + facet_wrap(~dist, scales='free') + guides(fill=FALSE) 
               
```

---

## Binomial test

_Step 1: Write the null and alternative hypotheses_

Assume that the true population proportion $p=p_0$, where $p_0$ is some constant value. The hypotheses we’re interested in testing are:

$$H_0: p = p_0$$

--

$$H_A: p (<, >, \ne) p_0$$

--
  
_Step 2: Identify the test statistic_

The data we'll need from our sample is the number of successes $x$ and the sample size $n$.

---

## Binomial test

_Step 3: Calculate the $p$-value_

We’ll use the binomial distribution with $p=p_0$ to calculate the $p$-value.

--

1. Build a binomial distribution based on $H_0: p = p_0$.

--

2. Calculate the probability of observing a "more extreme" result using this binomial distribution.

---

## Binomial test

.bg-washed-blue.b--blue.ba.ph3[
__Example__: A 2013 report in the New England Journal of Medicine by Wolchok et al. reported the results of a study in which patients were treated with both nivolumab and ipilimumab. Fifty-three patients were given the new regimens concurrently, and the response to therapy could be evaluated in 52 of the 53. Of the 52 evaluable patients, 21 (40%) experienced a response according to commonly accepted criteria. In previous studies, the proportion of patients responding to one of these agents was 30% or less. How might one compare the new data to past results?
]

$$H_0: p = 0.30$$

--

If the new drugs represent an improvement, then the resposne rate should be greater than 30%.

$$H_A: p > 0.30$$

---

## Binomial test

We have two "test statistics": the number of patients who improved (`x=21`), and the number of trials (`n=52`).

```{r, echo=FALSE}
data <- tibble(x = 0:52,
               p=dbinom(0:52, size=52, prob=0.30)) %>%
  mutate(improve=ifelse(x>=21, 1, 0))
data %>% ggplot(aes(x=x, y=p)) + geom_col(aes(fill=as.factor(improve))) + guides(fill=FALSE)
```

What's the probability that 21 patients or more would improve, __if the true improvement rate is 30%__?

---

## Binomial test

Instead of calculating probabilities directly, we can use a function in R called `binom.test()`.

```{r, echo=FALSE}
binom.test(x=21, n=52, p=0.30, alternative='greater')
```

---

## Binomial test

_Step 4: Make a conclusion to the research question_
  
- There may be _strong_ evidence to reject $H_0$ if $p-value < \alpha$.

--

- There may _not_ be evidence to reject $H_0$ if $p-value > \alpha$.

--

Remember that sample size, data quality, choice of $\alpha$, and consequences matter!

---

## Binomial test

.bg-washed-blue.b--blue.ba.ph3[
__Example__: Male radiologists have long suspected that they tend to have fewer sons than daughters. In a random sample of 87 children of "highly irradiated" male radiologists, 30 were male. Assume that the population proportion of male births is 0.519 (in the human population male babies are slightly more likely than female babies). Is there significant evidence to show male radiologists are less likely to have male babies?
]

---

## Binomial test

Is there significant evidence to show male radiologists are less likely to have male babies?

```{r, eval=FALSE}
binom.test(x=___, n=___, p=___, alternative='___')
```

---

## Binomial test

Is there significant evidence to show male radiologists are less likely to have male babies?

```{r}
binom.test(x=30, n=87, p=0.519, alternative='less')
```

---

## Standard error of a proportion

.bg-washed-blue.b--blue.ba.ph3[
__Example__: Estimate the standard error of the sample proportion of male offspring from male radiologists. Remember $\hat{p}= 30/87$.
]

---

## Confidence interval for a proportion

We’ll consider two choices:
  
1.	Standard “Wald” confidence interval: based on the normal approximation to the sampling distribution

--

2.	Clopper-Pearson confidence interval: based on the binomial distribution

---

## Wald confidence interval

.bg-washed-yellow.b--yellow.ba.ph3[__Wald interval__: calculated based on the Central Limit Theorem and the normal distribution

$$\hat{p} \pm 1.96 \times SE(\hat{p})$$

]

--

- The normal distribution approximation can be inaccurate when $n$ is small or $p$ is "extreme"

---

## Wald confidence interval

.bg-washed-blue.b--blue.ba.ph3[
__Example__: Calculate and interpret a  Wald confidence interval for the proportion of male babies born to male radiologists. Remember $\hat{p}= 30/87$.
]

---

## Clopper-Pearson confidence interval

A another alternative is the __Clopper-Pearson confidence interval__, which is based on the binomial distribution. 

The idea here is to take all of the values of

$$H_0: p = p_0$$

for which we fail to reject the null hypothesis, and set those as the confidence interval!

--

- Also called the exact binomial confidence interval, because it's based on exact probabilities from a binomial distribution.

---

## Clopper-Pearson confidence interval

The Clopper-Pearson interval is difficult to calculate by hand, but easy for R.

```{r}
binom.test(x=30, n=87, conf.level=0.95)
```

--

- There are other confidence intervals we could use. As $n \rightarrow \infty$, they tend to converge.

---

## Comparing intervals

.bg-washed-blue.b--blue.ba.ph3[
__Example__: A 2013 report in the New England Journal of Medicine by Wolchok et al. reported the results of a study in which patients were treated with both nivolumab and ipilimumab. Fifty-three patients were given the new regimens concurrently, and the response to therapy could be evaluated in 52 of the 53. Of the 52 evaluable patients, 21 (40%) experienced a response according to commonly accepted criteria. In previous studies, the proportion of patients responding to one of these agents was 30% or less. 

Calculate and interpret a Wald confidence interval and a Clopper-Pearson confidence interval. How do they compare?
]

---

## Comparing confidence intervals

Calculate and interpret a Wald confidence interval and a Clopper-Pearson confidence interval. How do they compare?

```{r, echo=TRUE}
# Wald interval
p <- 21/52
n <- 52

p + c(-1, 1)*1.96*sqrt(p*(1-p)/n)
```

---

## Comparing confidence intervals

Calculate and interpret a Wald confidence interval and a Clopper-Pearson confidence interval. How do they compare?

```{r, echo=TRUE}
# Clopper-Pearson
binom.test(x=21, n=52, conf.level=0.95)
```

---
class: inverse

# 8.2: Inference for the difference of two proportions

- Sampling distribution for $p_1 - p_2$

--

- Confidence intervals for $p_1 - p_2$

---

## Sampling distribution of $p_1-p_2$

The difference in two sample proportions, $\hat{p}_1 - \hat{p}_2$ tends to follow a normal model when:

--

- Each of the two samples are random samples from a population

--

- The two samples are idnependent of each other

--

- The sample sizes are "large enough": collectively, $n_1 p_1, \ n_2p_2, \ n_1(1-p_1), \ n_2(1-p_2) \ge 10$

--

The standard error of the difference is

$$SE_{\hat{p}_1-\hat{p}_2} = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}$$

---

## Confidence intervals for difference

.bg-washed-blue.b--blue.ba.ph3[__Example__: The way a question is phrased can influence a person's response. For example, Pew Research Center conducted a survey with the following question:

_As you may know, by 2014 nearly all Americans will be required to have health insurance. [People who do not buy insurance will pay a penalty] while [People who cannot afford it will receive financial help from the government]. Do you approve or disapprove of this policy?_

The statements in brackets were randomized: either they were kept in this order or switched.
]

---

## Confidence intervals for difference

Calculate and interpret a 95% confidence interval for the difference in the proportion who would agree.

Order|Sample size|Approve (%)|Disapprove (%)|Other (%)
----|----|-----|-----|-----
Original|771|47|49|3
Reversed|732|34|63|3

---

## Confidence intervals for difference

.bg-washed-blue.b--blue.ba.ph3[
__Example__: The use of screening mammograms for breast cancer has been con- troversial for decades because the overall benefit on breast cancer mortality is uncertain. Several large randomized studies have been conducted in an attempt to estimate the effect of mammogram screening. A 30-year study to investigate the effectiveness of mammograms versus a standard non-mammogram breast cancer exam was conducted in Canada with 89,835 female participants. During a 5-year screening period, each woman was randomized to either receive annual mammograms or standard physical exams for breast cancer. During the 25 years following the screening period, each woman was screened for breast cancer according to the standard of care at her health care center.
]

---

## Confidence intervals for difference

Calculate and interpret a 95% confidence interval for the difference in deaths due to breast cancer.

Group|Died from breast cancer|Did not die from breast cancer
----|----|-----
Mammogram|500|44,425
Control|505|44,405

---
class: inverse

# 8.3: Association between categorical variables

- Chi-square test for independence

---

## Association

.bg-washed-blue.b--blue.ba.ph3[
__Example__: The use of screening mammograms for breast cancer has been con- troversial for decades because the overall benefit on breast cancer mortality is uncertain. Several large randomized studies have been conducted in an attempt to estimate the effect of mammogram screening. A 30-year study to investigate the effectiveness of mammograms versus a standard non-mammogram breast cancer exam was conducted in Canada with 89,835 female participants. During a 5-year screening period, each woman was randomized to either receive annual mammograms or standard physical exams for breast cancer. During the 25 years following the screening period, each woman was screened for breast cancer according to the standard of care at her health care center. __Is there evidence that the screening method is associated with the outcome__?
]

---

## Chi-square test for independence

.bg-washed-yellow.b--yellow.ba.ph3[__Chi-square test for independence__: procedure for determining whether or not two categoricall variables are associated

- $H_0$: The "row" variable is independent of the "column" variable
- $H_A$: There is an association between the "row" variable and the "column" variable
]

---

# Chi-square distribution

The $\chi^2$ (chi-square) test statistic is:

$$\chi^2 = \sum_{i=1}^k \frac{(O_i - E_i)^2}{E_i}$$

where $k$ is the number of categories, $O_i$ is the "observed" count in category $i$, and $E_i$ is the "expected" count in category $i$ under our model.

---
  
## Chi-square distribution
  
This test statistic follows a probability distribution called the $\chi^2$ distribution. 

--

- Defined on positive values only.
- Right-skewed probability distribution.
- The higher the number of categories, $k$, the higher the expected value of the  test statistic.

---

## Chi-square distribution

How does the chi-square distribution change as $k$ changes?

```{r, message=FALSE, echo=FALSE}
x <- seq(from=0, to=25, length=100)
p <- c(dchisq(x, df=1), dchisq(x, df=2), dchisq(x, df=4), dchisq(x, df=9), dchisq(x, df=14), dchisq(x, df=19))
dist <- c(rep('Chi-square (k=02)', 100), rep('Chi-square (k=03)', 100),
         rep('Chi-square (k=05)', 100), rep('Chi-square (k=10)', 100),
         rep('Chi-square (k=15)', 100), rep('Chi-square (k=20)', 100))

data <- tibble(x=rep(x,6), p, dist)
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

data %>% ggplot(aes(x=x, y=p)) + geom_area(aes(fill=dist)) + geom_line() + facet_wrap(~dist, scales='free') + scale_fill_manual(values=cbPalette) + guides(fill=FALSE)
```

---

## Chi-square distribution

The $\chi^2$ distribution has a single parameter: degrees of freedom (df)

$$df = k-1$$

--

The $p$-value in a __chi-square test__:

```{r, message=FALSE, echo=FALSE}
data %>% filter(dist=='Chi-square (k=05)') %>% mutate(extreme=ifelse(x>=7, 'Yes', 'No')) %>%
  ggplot(aes(x=x, y=p)) + geom_area(aes(fill=extreme)) + geom_line() + geom_vline(xintercept=7, col='blue', lwd=2.7) +  scale_fill_manual(values=cbPalette) + guides(fill=FALSE)
```

---

## Chi-square test for independence

__Test statistic__: 

$$\chi^2 = \sum_{i=1}^r \sum_{j=1}^c \frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$

--

Some rules of thumb must be satisfied:

--

1.	None of the categories should have an expected frequency <1.
2.	No more of than 20% of the categories should have expected frequency <5.

--

These conditions help ensure the sample size is "large enough".

---

## Chi-square test

.bg-washed-blue.b--blue.ba.ph3[
__Example__: Consider the breast cancer screening problem. Is there evidence that screening method is associated with outcome?
]

Data: 

Group|Died from breast cancer|Did not die from breast cancer
----|----|-----
Mammogram|500|44,425
Control|505|44,405

---

## Chi-square test

If there is no association, the proportions in each group should be approximately equal.

```{r, echo=5, warning=FALSE, message=FALSE}
group <- c(rep('Mammogram', 500+44425), rep('Control', 505+44405))
outcome <- c(rep('died', 500), rep('survived',44425), rep('died', 505), rep('survived', 44405))

screening <- tibble(group, outcome)

library(mosaic)

screening %>% ggplot(aes(x=outcome)) + geom_bar(aes(fill=group)) 
```

---

## Chi-square test

```{r, echo=TRUE, warning=FALSE, message=FALSE}
screening %>% ggplot(aes(x=outcome)) +
  geom_bar(aes(fill=group), position='fill') + #<<
  scale_y_continuous(labels = scales::percent) + #<<
  labs(y='proportion')
```

---

## Chi-square test

```{r, echo=TRUE}
table <- tally(group~outcome, data=screening)
chisq.test(table)
```

---

## Chi-square test

.bg-washed-blue.b--blue.ba.ph3[

__Example__: Malaria, which kills more than a million people each year worldwide, is caused by a _Plasmodium_ that spreads between hosts by infected mosquitoes. The more people bitten by each infected mosquito, the higher the transmission rates of malaria. Does infection by plasmodium cause a mosquito to bite more people?

Researchers captured 262 mosquitoes that had human blood in their systems and measured two attributes: whether the mosquitoes were infected with malaria, and whether they had fed on the blood of more than one person (assessed by DNA fingerprinting the blood in the mosquito).

Of 173 uninfected mosquitoes, 16 had bit multiple people. Of 89 infected mosquitoes, 20 had bit multiple people.
]

---

## Chi-square test

Of 173 uninfected mosquitoes, 16 had bit multiple people. Of 89 infected mosquitoes, 20 had bit multiple people.

```{r, echo=4}
infected <- c(rep('Yes', 89), rep('No', 173))
bites <- c(rep('Multiple', 20), rep('One', 89-20),
           rep('Multiple', 16), rep('One', 173-16))
malaria <- tibble(infected, bites)

tally(infected~bites, data=malaria)
```

---

## Chi-square test

Of 173 uninfected mosquitoes, 16 had bit multiple people. Of 89 infected mosquitoes, 20 had bit multiple people.

```{r, echo=FALSE}
counts <- c((1-0.159292)*173, 0.159292*173,
            (1-0.159292)*89, 0.159292*89)
expected <- tibble(infected = c('No', 'No', 'Yes', 'Yes'), counts)

malaria %>% ggplot(aes(x=infected)) +   geom_bar(aes(fill=bites), position='fill') + #<<
  scale_y_continuous(labels = scales::percent) + #<< 
labs(y='proportion')
```

---

## Chi-square test

```{r, echo=TRUE}
chisq.test(table)
```

---
class: inverse

# 8.4: "Fit" of a distribution

- Chi-square test for goodness of fit

---

## Goodness-of-fit tests

In general, _goodness-of-fit tests_ are used to compare a data set to some known distribution.

.bg-washed-yellow.b--yellow.ba.ph3[
__Chi-square goodness-of-fit test__: compares the observed frequencies in the data set to the expected frequencies under the null hypothesis or probability model]

The $\chi^2$ (chi-square) test statistic is:

$$\chi^2 = \sum_{i=1}^k \frac{(O_i - E_i)^2}{E_i}$$

where $k$ is the number of categories, $O_i$ is the "observed" count in category $i$, and $E_i$ is the "expected" count in category $i$ under our model.
]

---

## Chi-square test

There are two “rules of thumb” that should be checked before using this test.

1.	None of the categories should have an expected frequency <1.
2.	No more of than 20% of the categories should have expected frequency <5.

--

- These conditions ensure that the sample size is “large enough” for the chi-square distribution to be a reasonable fit for the null distribution. 

- Most statistical software, including R, will warn you if either rule of thumb may be violated.

---

## Chi-square goodness of fit

.bg-washed-blue.b--blue.ba.ph3[
__Example__: Melanoma is a rare form of skin cancer that accounts for the great majority of skin cancer fatalities. UV exposure is a major risk factor for melanoma. Some body parts are regularly more exposed to the sun than others. A random sample of 310 women diagnosed with melanoma were classified according to the known location of the melanoma on their bodies. 

Location|Head/neck|Trunk|Upper limbs|Lower limbs
---|---|---|---|---
Count|45|80|34|151

Assume that these body parts represent roughly equal skin areas. Do the data support the hypothesis that melanoma occurs evenly on the body?
]

---

## Chi-square goodness of fit

```{r, echo=FALSE}
data <- tibble(
  location = c(rep('Head/neck', 45), rep('Trunk', 80), rep('Upper limbs', 34), rep('Lower limbs', 151))
)

expected <- tibble(location=c('Head/neck', 'Trunk', 'Upper limbs', 'Lower limbs'),
                   counts = rep(310/4, 4))

data %>% ggplot(aes(x=location)) + geom_bar(aes(fill=location)) + guides(fill=FALSE) +
  geom_col(data = expected, aes(x = location, y = counts), col='black', alpha=0)
```

---

## Chi-square goodness of fit

Assume that these body parts represent roughly equal skin areas. Do the data support the hypothesis that melanoma occurs evenly on the body?

```{r, echo=TRUE}
observed <- c(45, 80, 34, 151)
expected <- c(0.25, 0.25, 0.25, 0.25)
chisq.test(x=observed, p=expected)
```

---

## Chi-square goodness of fit

.bg-washed-blue.b--blue.ba.ph3[
__Example__: The FDA has recently requested that every effort be made to include individuals of all major ethnic backgrounds when enrolling subjects in clinical trials. A randomly chosen article in the _New England Journal of Medicine_ describes the efficacy of calcium and vitamin D supplementation in preventing hip and other fractures in healthy post-menopausal women. The table below shows the breakdown by major ethnic group of the subjects in the study, as well as the percent of individuals from each ethnicity in the general American population at the time of the study.

Ethnicity|White|Black|Hispanic|Asian/Pacific|Native Amer.
---|---|---|---|---|---
Study|30153|3317|1507|722|149
% in US|75.6|10.8|9.1|3.8|0.7
]

---

## Chi-square goodness of fit

```{r, echo=FALSE}
data <- tibble(
  group = c(rep('White', 30153), 
            rep('Black', 3317), 
            rep('Hispanic', 1507), 
            rep('Asian/Pacific', 722),
            rep('Native American', 149)))

expected <- tibble(group=c('White', 'Black', 'Hispanic', 
                           'Asian/Pacific', 'Native American'),
                   counts = c(0.756, 0.108, 0.091, 0.038, 0.007)*35848)

data %>% ggplot(aes(x=group)) + geom_bar(aes(fill=group)) + guides(fill=FALSE) +
  geom_col(data = expected, aes(x = group, y = counts), col='black', alpha=0)
```

---

## Chi-square goodness of fit

The FDA has recently requested that every effort be made to include individuals of all major ethnic backgrounds when enrolling subjects in clinical trials. 

Ethnicity|White|Black|Hispanic|Asian/Pacific|Native Amer.
---|---|---|---|---|---
Study|30153|3317|1507|722|149
% in US|75.6|10.8|9.1|3.8|0.7

Did this study successfully match the ethnic diversity of the American population?

---

## Chi-square goodness of fit

Did this study successfully match the ethnic diversity of the American population?

```{r, echo=TRUE}
observed <- c(30153, 3317, 1507, 722, 149)
expected <- c(0.756, 0.108, 0.091, 0.038, 0.007)
chisq.test(x=observed, p=expected)
```
